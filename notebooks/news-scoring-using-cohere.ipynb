{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import os\n",
    "import sys\n",
    "import dvc.api\n",
    "import pandas as pd\n",
    "import dataframe_image as dfi\n",
    "from dotenv import load_dotenv\n",
    "import cohere\n",
    "from cohere.classify import Example\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--> <Logger dataCleaner (WARNING)>\n",
      "logger <Logger dataCleaner (DEBUG)> created at path: ../logs/cleaner_root.log\n",
      "Data cleaner in action\n",
      "--> <Logger dataVisualizer (WARNING)>\n",
      "logger <Logger dataVisualizer (DEBUG)> created at path: ../logs/visualizer_root.log\n",
      "Data visualizer in action\n"
     ]
    }
   ],
   "source": [
    "# adding and setting up scripts\n",
    "sys.path.append('.')\n",
    "sys.path.append('..')\n",
    "sys.path.insert(1, '../scripts/')\n",
    "import defaults as defs\n",
    "import dataCleaner as dc\n",
    "import dataVisualizer as dv\n",
    "# load your environment\n",
    "load_dotenv()\n",
    "# use your own api key here\n",
    "cohere_api_key = os.getenv('cohere_api_key')\n",
    "cleaner = dc.dataCleaner('news scoring using co:here API notebook')\n",
    "visualizer = dv.dataVisualizer('news scoring using co:here API notebook')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "news data path: /home/f0x-tr0t/Documents/dvc-store//50/1fbc56d932bcb51d74876281ec8f71\n"
     ]
    }
   ],
   "source": [
    "# pandas settings\n",
    "pd.set_option('display.max_columns', 30)\n",
    "\n",
    "# version of the data\n",
    "# v1 : local-store\n",
    "version = 'v1'\n",
    "\n",
    "# set up the dat url\n",
    "news_url = dvc.api.get_url(path = defs.news_local_path, \n",
    "                       repo = defs.repo, \n",
    "                       rev = version)\n",
    "\n",
    "# print news path\n",
    "print(f'news data path: {news_url}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reading csv files\n",
    "DateCols = ['timestamp']\n",
    "missing_values = [\"n/a\", \"na\", \"undefined\", '?', 'NA', 'undefined']\n",
    "\n",
    "news_data = pd.read_csv(news_url, na_values=missing_values, parse_dates=DateCols, low_memory=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# News scoring using co:here API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting up api key\n",
    "# use your own api key here\n",
    "co = cohere.Client(cohere_api_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting up model parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Domain', 'Title', 'Description', 'Body', 'Link', 'timestamp',\n",
       "       'Analyst_Average_Score', 'Analyst_Rank', 'Reference_Final_Score'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news_data.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* As we have seen in the demo, it will be best to classify the scores first prior to requesting the API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.00    7\n",
       "1.33    1\n",
       "1.66    1\n",
       "0.33    1\n",
       "Name: Analyst_Average_Score, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news_data['Analyst_Average_Score'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4    7\n",
       "2    1\n",
       "1    1\n",
       "3    1\n",
       "Name: Analyst_Rank, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news_data['Analyst_Rank'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* We can classify the average score into 6 categories.\n",
    "    * 1- lovely    ---   below 0.33\n",
    "    * 2- good         ---    between 0.33 and 0.66\n",
    "    * 3- neutral      ---    between 0.66 and 1.22\n",
    "    * 4- risky      ---     between 1.22 and 1.55\n",
    "    * 5- detrimental --- greater than: 1.55"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classifyBasedOnScore(df: pd.DataFrame) -> str:\n",
    "    \"\"\"\n",
    "    Classify based on score.\n",
    "    Parameters\n",
    "    =--------=\n",
    "    df: pandas dataframe\n",
    "        the data frame to classify\n",
    "    \"\"\"\n",
    "    if df['Analyst_Average_Score'] <= 0.33:\n",
    "        return 'lovely'\n",
    "    if df['Analyst_Average_Score'] <= 0.66:\n",
    "        return 'good'\n",
    "    if df['Analyst_Average_Score'] <= 1.22:\n",
    "        return 'neutral'\n",
    "    if df['Analyst_Average_Score'] <= 1.55:\n",
    "        return 'risky'\n",
    "    if df['Analyst_Average_Score'] > 1.55:\n",
    "        return 'detrimental'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "news_data['class'] = news_data.apply(lambda news_data: classifyBasedOnScore(df= news_data), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Analyst_Average_Score</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00</td>\n",
       "      <td>lovely</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.00</td>\n",
       "      <td>lovely</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.00</td>\n",
       "      <td>lovely</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.00</td>\n",
       "      <td>lovely</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.00</td>\n",
       "      <td>lovely</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.33</td>\n",
       "      <td>risky</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.00</td>\n",
       "      <td>lovely</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.66</td>\n",
       "      <td>detrimental</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.33</td>\n",
       "      <td>lovely</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.00</td>\n",
       "      <td>lovely</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Analyst_Average_Score        class\n",
       "0                   0.00       lovely\n",
       "1                   0.00       lovely\n",
       "2                   0.00       lovely\n",
       "3                   0.00       lovely\n",
       "4                   0.00       lovely\n",
       "5                   1.33        risky\n",
       "6                   0.00       lovely\n",
       "7                   1.66  detrimental\n",
       "8                   0.33       lovely\n",
       "9                   0.00       lovely"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news_data[['Analyst_Average_Score', 'class']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Now we can use this class feature for the co:here model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting up classify parameters\n",
    "\n",
    "# model type to use\n",
    "model_type='large'\n",
    "\n",
    "# TODO: change these to the news body\n",
    "# the news sentences (body) to get classification for\n",
    "classification_inputs=[\"Am I still able to return my order?\", \"When can I expect my package?\"]\n",
    "\n",
    "# TODO: change these to the news body and analyst average score\n",
    "# the existing news prepared in these example formats to feed to the model\n",
    "\n",
    "# TODO: set up the news classifications like this\n",
    "type_one = 'Shipping and handling policy'\n",
    "type_two = 'Start return or exchange'\n",
    "type_three = 'Track orders'\n",
    "\n",
    "# TODO: set up the news examples like this\n",
    "prompt_examples = [Example(\"Do you offer same day shipping?\", type_one),\n",
    "            Example(\"Can you ship to Italy?\", type_one),\n",
    "            Example(\"How long does shipping take?\", type_one),\n",
    "            Example(\"Can I buy online and pick up in store?\", type_one),\n",
    "            Example(\"What are your shipping options?\", type_one),\n",
    "\n",
    "            Example(\"My order arrived damaged, can I get a refund?\", type_two),\n",
    "            Example(\"You sent me the wrong item\", type_two),\n",
    "            Example(\"I want to exchange my item for another colour\", type_two),\n",
    "            Example(\"I ordered something and it wasn’t what I expected. Can I return it?\", type_two),\n",
    "            Example(\"What’s your return policy?\", type_two),\n",
    "\n",
    "            Example(\"Where’s my package?\", type_three),\n",
    "            Example(\"When will my order arrive?\", type_three),\n",
    "            Example(\"What’s my shipping number?\", type_three),\n",
    "            Example(\"Which carrier is my package with?\", type_three),\n",
    "            Example(\"Is my package delayed?\", type_three)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting up classify parameters and examples \n",
    "\n",
    "response = co.classify(\n",
    "  model=model_type,\n",
    "  inputs=classification_inputs,\n",
    "  examples=prompt_examples\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The confidence levels of the labels are:\n",
      "[cohere.Classification {\n",
      "\tinput: Am I still able to return my order?\n",
      "\tprediction: Start return or exchange\n",
      "\tconfidence: [cohere.Confidence {\n",
      "\tlabel: Shipping and handling policy\n",
      "\tconfidence: 0.32005534\n",
      "}, cohere.Confidence {\n",
      "\tlabel: Start return or exchange\n",
      "\tconfidence: 0.5335526\n",
      "}, cohere.Confidence {\n",
      "\tlabel: Track orders\n",
      "\tconfidence: 0.14639212\n",
      "}]\n",
      "}, cohere.Classification {\n",
      "\tinput: When can I expect my package?\n",
      "\tprediction: Track orders\n",
      "\tconfidence: [cohere.Confidence {\n",
      "\tlabel: Shipping and handling policy\n",
      "\tconfidence: 0.27741268\n",
      "}, cohere.Confidence {\n",
      "\tlabel: Start return or exchange\n",
      "\tconfidence: 0.30839407\n",
      "}, cohere.Confidence {\n",
      "\tlabel: Track orders\n",
      "\tconfidence: 0.41419324\n",
      "}]\n",
      "}]\n"
     ]
    }
   ],
   "source": [
    "# finally get the classification for the  news and convert it back to a numerical range factor\n",
    "\n",
    "print('The confidence levels of the labels are:\\n{}'.format(response.classifications))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Finally receive the prediction of the classification"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
